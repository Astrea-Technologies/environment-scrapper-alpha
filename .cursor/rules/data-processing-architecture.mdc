---
description: Data Processing Architecture Specification for the Political Social Media Analysis Platform.
globs: 
alwaysApply: false
---
# Data Processing Architecture (MVP Version)

## 1. Technology Stack Overview

| Component | Technology | Version | Purpose | MVP Status |
|-----|---|---|---|---|
| Text Processing | spaCy | 3.6+ | NLP and entity recognition | ✅ Included |
| Sentiment Analysis | Transformers | 4.28+ | Content sentiment detection | ✅ Included |
| Vector Embeddings | sentence-transformers | 2.2.2+ | Text embedding generation | ✅ Included |
| Machine Learning | scikit-learn | 1.2+ | Classification and regression | ✅ Included |
| Full-Text Search | MongoDB Atlas Search | N/A | Content search capabilities | ✅ Included |
| Task Queue | Celery | 5.3.0+ | Asynchronous task processing | ❌ **NOT in MVP** |
| Message Broker | RabbitMQ | 3.12+ | Task distribution and messaging | ❌ **NOT in MVP** |
| Stream Processing | Apache Kafka | 3.4+ | Real-time event streaming | ❌ **NOT in MVP** |

## 2. Processing Pipeline Components

### 2.1 Data Collection Components

#### Platform Collectors
- **Standardized Base Collector**: `BaseCollector` class providing common functionality
- **Platform-Specific Collectors**:
  - `InstagramCollector`: Instagram data collection and transformation
  - `FacebookCollector`: Facebook data collection and transformation
  - `TwitterCollector`: Twitter/X data collection and transformation
  - `TikTokCollector`: TikTok data collection and transformation

#### Collection Features
- **Rate Limiting**: Built-in respect for platform API constraints
- **Error Handling**: Robust error handling and retry mechanisms
- **Data Transformation**: Standardized data structures across platforms
- **Validation**: Schema validation using Pydantic models

### 2.2 Data Models

#### MongoDB Schema Models
```python
class SocialMediaPost(BaseModel):
    platform_id: str
    platform: str
    account_id: UUID
    content_type: str
    short_code: Optional[str]
    url: Optional[HttpUrl]
    content: PostContent
    metadata: PostMetadata
    engagement: PostEngagement
    analysis: Optional[PostAnalysis]
    child_posts: Optional[List[ChildPost]]
    video_data: Optional[VideoData]
    vector_id: Optional[str]

class SocialMediaComment(BaseModel):
    platform_id: str
    platform: str
    post_id: str
    post_url: Optional[HttpUrl]
    user_id: str
    user_name: str
    content: CommentContent
    metadata: CommentMetadata
    engagement: CommentEngagement
    replies: List[CommentReply]
    analysis: Optional[CommentAnalysis]
    user_details: Optional[CommentUserDetails]
    vector_id: Optional[str]
```

### 2.3 Data Processing Flow

1. **Collection**:
   - Platform collector fetches data from social media API
   - Data is transformed to standardized format
   - Validation against Pydantic models

2. **Storage**:
   - Posts and comments stored in MongoDB
   - Profile data stored in PostgreSQL
   - References maintained between databases

3. **Analysis** (Background Processing):
   - Content analysis (sentiment, topics)
   - Engagement metrics calculation
   - Vector embedding generation

## 3. Task Processing (MVP Implementation)

### 3.1 Task Manager
```python
class TaskManager:
    """Simple in-memory task management system for MVP."""
    
    def __init__(self):
        self.tasks = {}
        self.status = {}
    
    async def create_task(self, task_type: str, params: dict):
        """Create and track a new task."""
        task_id = str(uuid4())
        self.tasks[task_id] = {
            "type": task_type,
            "params": params,
            "status": "pending",
            "created_at": datetime.utcnow()
        }
        return task_id
    
    async def get_task_status(self, task_id: str):
        """Get the current status of a task."""
        return self.tasks.get(task_id, {}).get("status", "not_found")
```

### 3.2 Background Tasks
- Uses FastAPI's `BackgroundTasks` for asynchronous processing
- Simple task queue with in-memory status tracking
- Basic retry mechanism for failed tasks

## 4. Data Transformation

### 4.1 Platform-Specific Transformers
Each collector implements transformation methods:
```python
def transform_post(self, raw_post: Dict[str, Any], account_id: UUID) -> Dict[str, Any]:
    """Transform platform-specific post data to standard format."""
    
def transform_comment(self, raw_comment: Dict[str, Any], post_id: str) -> Dict[str, Any]:
    """Transform platform-specific comment data to standard format."""
    
def transform_profile(self, raw_profile: Dict[str, Any]) -> Dict[str, Any]:
    """Transform platform-specific profile data to standard format."""
```

### 4.2 Standardization Rules
- Consistent datetime formats
- Normalized engagement metrics
- Platform-agnostic content structure
- Uniform handling of media content

## 5. Error Handling and Validation

### 5.1 Error Types
- API rate limiting errors
- Network connectivity issues
- Data validation errors
- Transformation errors

### 5.2 Validation Strategy
- Schema validation using Pydantic models
- Data type checking and conversion
- Required field verification
- Cross-reference validation

## 6. Future Enhancements (Post-MVP)

### 6.1 Task Queue System
- Implementation of Celery for robust task processing
- RabbitMQ integration for message queuing
- Distributed task execution
- Task prioritization and scheduling

### 6.2 Stream Processing
- Kafka integration for real-time data streaming
- Event-driven architecture
- Real-time analytics pipeline
- Notification system

### 6.3 Caching Layer
- Redis integration for caching
- Performance optimization
- Real-time metrics
- Session management

## 7. Dependencies (MVP)

| Dependency | Version | Purpose |
|---|---|---|
| spacy | 3.6.0+ | Natural language processing |
| transformers | 4.28.0+ | Machine learning models |
| scikit-learn | 1.2.0+ | Classical machine learning tools |
| sentence-transformers | 2.2.2+ | Text embedding generation |
| pydantic | 2.0+ | Data validation and settings management |
| motor | 3.2.0+ | Async MongoDB driver |
| sqlmodel | 0.0.8+ | SQL database ORM |