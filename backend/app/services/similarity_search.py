"""
Similarity search service for finding similar content using vector embeddings.

This module provides a service for performing similarity searches against
Pinecone vector database in the Political Social Media Analysis Platform.
It works with embeddings generated by OpenAI's embedding models, which
provide excellent performance for multilingual content including Spanish.
"""

import asyncio
import logging
from datetime import datetime
from functools import partial
from typing import Any, Dict, List, Optional, Tuple, Union, cast
from uuid import UUID
from concurrent.futures import ThreadPoolExecutor

import backoff
import numpy as np
# Import pinecone dynamically when needed
# from pinecone.exceptions import PineconeException

from app.core.config import settings
from app.db.connections import get_pinecone
from app.services.vector_embedding import VectorEmbeddingService


logger = logging.getLogger(__name__)


class SimilaritySearchService:
    """
    Service for performing similarity searches using vector embeddings.
    
    This service provides methods for finding similar content in the Pinecone vector
    database, with options for filtering by metadata and configuring search parameters.
    """
    
    def __init__(
        self,
        pinecone_index=None,
        embedding_service: Optional[VectorEmbeddingService] = None,
        default_top_k: int = 10,
        default_threshold: float = 0.7,
        max_workers: int = 4
    ):
        """
        Initialize the similarity search service.
        
        Args:
            pinecone_index: Pinecone index instance. If None, gets the default index.
            embedding_service: VectorEmbeddingService instance for generating embeddings.
                              If None, creates a new instance.
            default_top_k: Default number of results to return.
            default_threshold: Default similarity threshold (0.0 to 1.0).
            max_workers: Maximum number of worker threads for parallel processing.
        """
        self._pinecone_index = pinecone_index or get_pinecone()
        self._pinecone_available = self._pinecone_index is not None
        self._embedding_service = embedding_service or VectorEmbeddingService(pinecone_index=self._pinecone_index)
        self._default_top_k = default_top_k
        self._default_threshold = default_threshold
        self._executor = ThreadPoolExecutor(max_workers=max_workers)
        
        if not self._pinecone_available:
            logger.warning("Pinecone is not available - similarity search operations will be disabled")
    
    @staticmethod
    def _build_filter_dict(
        content_type: Optional[str] = None,
        platform: Optional[str] = None,
        account_id: Optional[Union[UUID, str]] = None,
        entity_id: Optional[Union[UUID, str]] = None,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        additional_filters: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Build a filter dictionary for Pinecone queries.
        
        Args:
            content_type: Optional filter by content type ('post' or 'comment').
            platform: Optional filter by platform.
            account_id: Optional filter by account ID.
            entity_id: Optional filter by entity ID.
            start_date: Optional filter for content created after this date.
            end_date: Optional filter for content created before this date.
            additional_filters: Optional additional filter conditions.
            
        Returns:
            A dictionary with filter conditions for Pinecone queries.
        """
        filter_dict: Dict[str, Any] = {}
        
        if content_type:
            filter_dict["content_type"] = content_type
        
        if platform:
            filter_dict["platform"] = platform
        
        if account_id:
            filter_dict["account_id"] = str(account_id)
        
        if entity_id:
            filter_dict["entity_id"] = str(entity_id)
        
        # Date range filter
        if start_date or end_date:
            date_filter = {}
            
            if start_date:
                date_filter["$gte"] = start_date.isoformat()
            
            if end_date:
                date_filter["$lte"] = end_date.isoformat()
            
            if date_filter:
                filter_dict["created_at"] = date_filter
        
        # Add additional filters
        if additional_filters:
            filter_dict.update(additional_filters)
        
        return filter_dict
    
    @backoff.on_exception(
        backoff.expo,
        Exception,
        max_tries=5,
        jitter=backoff.full_jitter
    )
    async def search_by_text(
        self,
        query_text: str,
        top_k: Optional[int] = None,
        threshold: Optional[float] = None,
        namespace: str = "",
        content_type: Optional[str] = None,
        platform: Optional[str] = None,
        account_id: Optional[Union[UUID, str]] = None,
        entity_id: Optional[Union[UUID, str]] = None,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        additional_filters: Optional[Dict[str, Any]] = None,
        include_metadata: bool = True,
        include_values: bool = False
    ) -> List[Dict[str, Any]]:
        """
        Search for similar content using a text query.
        
        Args:
            query_text: The text to search for similar content.
            top_k: Maximum number of results to return.
            threshold: Minimum similarity score (0.0 to 1.0) for results.
            namespace: Optional namespace to search in.
            content_type: Optional filter by content type ('post' or 'comment').
            platform: Optional filter by platform.
            account_id: Optional filter by account ID.
            entity_id: Optional filter by entity ID.
            start_date: Optional filter for content created after this date.
            end_date: Optional filter for content created before this date.
            additional_filters: Optional additional filter conditions.
            include_metadata: Whether to include metadata in results.
            include_values: Whether to include vector values in results.
            
        Returns:
            List of dictionaries containing match results.
            
        Raises:
            Exception: If there's an error from the Pinecone API.
            ConnectionError: If there's a connection error.
            ValueError: If Pinecone is not available.
        """
        if not self._pinecone_available or not self._pinecone_index:
            logger.error("Pinecone not available - cannot perform similarity search")
            return []
            
        if not query_text.strip():
            logger.warning("Empty query text provided for similarity search")
            return []
        
        try:
            # Generate embedding for the query text
            query_embedding = await self._embedding_service.generate_embedding(query_text)
        except Exception as e:
            logger.error(f"Error generating embedding for query text: {str(e)}")
            raise
        
        # Call search by vector with the generated embedding
        return await self.search_by_vector(
            query_vector=query_embedding,
            top_k=top_k,
            threshold=threshold,
            namespace=namespace,
            content_type=content_type,
            platform=platform,
            account_id=account_id,
            entity_id=entity_id,
            start_date=start_date,
            end_date=end_date,
            additional_filters=additional_filters,
            include_metadata=include_metadata,
            include_values=include_values
        )
    
    @backoff.on_exception(
        backoff.expo,
        (Exception, ConnectionError),
        max_tries=5,
        jitter=backoff.full_jitter
    )
    async def search_by_vector(
        self,
        query_vector: np.ndarray,
        top_k: Optional[int] = None,
        threshold: Optional[float] = None,
        namespace: str = "",
        content_type: Optional[str] = None,
        platform: Optional[str] = None,
        account_id: Optional[Union[UUID, str]] = None,
        entity_id: Optional[Union[UUID, str]] = None,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        additional_filters: Optional[Dict[str, Any]] = None,
        include_metadata: bool = True,
        include_values: bool = False
    ) -> List[Dict[str, Any]]:
        """
        Search for similar content using a vector.
        
        Args:
            query_vector: The vector to search for similar content.
            top_k: Maximum number of results to return.
            threshold: Minimum similarity score (0.0 to 1.0) for results.
            namespace: Optional namespace to search in.
            content_type: Optional filter by content type ('post' or 'comment').
            platform: Optional filter by platform.
            account_id: Optional filter by account ID.
            entity_id: Optional filter by entity ID.
            start_date: Optional filter for content created after this date.
            end_date: Optional filter for content created before this date.
            additional_filters: Optional additional filter conditions.
            include_metadata: Whether to include metadata in results.
            include_values: Whether to include vector values in results.
            
        Returns:
            List of dictionaries containing match results.
            
        Raises:
            Exception: If there's an error from the Pinecone API.
            ConnectionError: If there's a connection error.
        """
        # Apply defaults
        top_k = top_k if top_k is not None else self._default_top_k
        threshold = threshold if threshold is not None else self._default_threshold
        
        # Build filter dictionary
        filter_dict = self._build_filter_dict(
            content_type=content_type,
            platform=platform,
            account_id=account_id,
            entity_id=entity_id,
            start_date=start_date,
            end_date=end_date,
            additional_filters=additional_filters
        )
        
        try:
            # Pinecone query is synchronous, so run in thread pool
            loop = asyncio.get_event_loop()
            
            # Convert numpy array to list for Pinecone
            vector_values = query_vector.tolist()
            
            response = await loop.run_in_executor(
                self._executor,
                partial(
                    self._pinecone_index.query,
                    vector=vector_values,
                    top_k=top_k,
                    namespace=namespace,
                    filter=filter_dict if filter_dict else None,
                    include_metadata=include_metadata,
                    include_values=include_values
                )
            )
            
            # Process and filter results by threshold
            matches = []
            
            for match in response.matches:
                if match.score >= threshold:
                    match_dict = {
                        "id": match.id,
                        "score": match.score
                    }
                    
                    if include_metadata and hasattr(match, "metadata") and match.metadata:
                        match_dict["metadata"] = match.metadata
                    
                    if include_values and hasattr(match, "values") and match.values:
                        match_dict["values"] = match.values
                    
                    matches.append(match_dict)
            
            return matches
        except Exception as e:
            logger.error(f"Error in vector search: {str(e)}")
            raise
    
    @backoff.on_exception(
        backoff.expo,
        (Exception, ConnectionError),
        max_tries=5,
        jitter=backoff.full_jitter
    )
    async def search_by_vector_id(
        self,
        vector_id: str,
        top_k: Optional[int] = None,
        threshold: Optional[float] = None,
        namespace: str = "",
        content_type: Optional[str] = None,
        platform: Optional[str] = None,
        account_id: Optional[Union[UUID, str]] = None,
        entity_id: Optional[Union[UUID, str]] = None,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        additional_filters: Optional[Dict[str, Any]] = None,
        include_metadata: bool = True,
        include_values: bool = False
    ) -> List[Dict[str, Any]]:
        """
        Search for similar content using an existing vector ID.
        
        Args:
            vector_id: ID of an existing vector to use for the search.
            top_k: Maximum number of results to return.
            threshold: Minimum similarity score (0.0 to 1.0) for results.
            namespace: Optional namespace to search in.
            content_type: Optional filter by content type ('post' or 'comment').
            platform: Optional filter by platform.
            account_id: Optional filter by account ID.
            entity_id: Optional filter by entity ID.
            start_date: Optional filter for content created after this date.
            end_date: Optional filter for content created before this date.
            additional_filters: Optional additional filter conditions.
            include_metadata: Whether to include metadata in results.
            include_values: Whether to include vector values in results.
            
        Returns:
            List of dictionaries containing match results.
            
        Raises:
            Exception: If there's an error from the Pinecone API.
            ConnectionError: If there's a connection error.
            ValueError: If the specified vector ID doesn't exist.
        """
        try:
            # First, fetch the vector from Pinecone
            loop = asyncio.get_event_loop()
            
            fetch_response = await loop.run_in_executor(
                self._executor,
                partial(
                    self._pinecone_index.fetch,
                    ids=[vector_id],
                    namespace=namespace
                )
            )
            
            if vector_id not in fetch_response.vectors:
                raise ValueError(f"Vector with ID {vector_id} not found")
            
            # Use the fetched vector for the search
            vector_values = fetch_response.vectors[vector_id].values
            
            # Call search by vector with the fetched vector
            return await self.search_by_vector(
                query_vector=np.array(vector_values),
                top_k=top_k,
                threshold=threshold,
                namespace=namespace,
                content_type=content_type,
                platform=platform,
                account_id=account_id,
                entity_id=entity_id,
                start_date=start_date,
                end_date=end_date,
                additional_filters=additional_filters,
                include_metadata=include_metadata,
                include_values=include_values
            )
        except ValueError:
            # Re-raise ValueError for client handling
            raise
        except Exception as e:
            logger.error(f"Error in vector ID search: {str(e)}")
            raise
    
    async def search_and_get_ids_only(
        self,
        query_text: str,
        **kwargs
    ) -> List[str]:
        """
        Search for similar content and return only the vector IDs.
        
        Args:
            query_text: The text to search for similar content.
            **kwargs: Additional arguments for search_by_text.
            
        Returns:
            List of vector IDs of matching content.
        """
        results = await self.search_by_text(
            query_text=query_text,
            include_metadata=False,
            include_values=False,
            **kwargs
        )
        
        return [result["id"] for result in results]
    
    async def filter_by_metadata(
        self,
        content_type: Optional[str] = None,
        platform: Optional[str] = None,
        account_id: Optional[Union[UUID, str]] = None,
        entity_id: Optional[Union[UUID, str]] = None,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        additional_filters: Optional[Dict[str, Any]] = None,
        namespace: str = "",
        limit: int = 100,
        include_metadata: bool = True
    ) -> List[Dict[str, Any]]:
        """
        Filter vectors by metadata without performing a similarity search.
        
        This is useful for finding content based on metadata criteria alone.
        
        Args:
            content_type: Optional filter by content type ('post' or 'comment').
            platform: Optional filter by platform.
            account_id: Optional filter by account ID.
            entity_id: Optional filter by entity ID.
            start_date: Optional filter for content created after this date.
            end_date: Optional filter for content created before this date.
            additional_filters: Optional additional filter conditions.
            namespace: Optional namespace to search in.
            limit: Maximum number of results to return.
            include_metadata: Whether to include metadata in results.
            
        Returns:
            List of dictionaries containing match results.
            
        Raises:
            Exception: If there's an error from the Pinecone API.
            ConnectionError: If there's a connection error.
        """
        # Build filter dictionary
        filter_dict = self._build_filter_dict(
            content_type=content_type,
            platform=platform,
            account_id=account_id,
            entity_id=entity_id,
            start_date=start_date,
            end_date=end_date,
            additional_filters=additional_filters
        )
        
        if not filter_dict:
            logger.warning("No filter criteria provided for metadata search")
            return []
        
        try:
            # Create a dummy vector for the query
            # This is needed because Pinecone doesn't have a pure metadata query API
            dummy_vector = [0.0] * settings.OPENAI_EMBEDDING_DIMENSION  # Use dimension from settings
            
            # Pinecone query is synchronous, so run in thread pool
            loop = asyncio.get_event_loop()
            
            response = await loop.run_in_executor(
                self._executor,
                partial(
                    self._pinecone_index.query,
                    vector=dummy_vector,
                    top_k=limit,
                    namespace=namespace,
                    filter=filter_dict,
                    include_metadata=include_metadata,
                    include_values=False
                )
            )
            
            # Process results
            matches = []
            
            for match in response.matches:
                match_dict = {
                    "id": match.id,
                }
                
                if include_metadata and hasattr(match, "metadata") and match.metadata:
                    match_dict["metadata"] = match.metadata
                
                matches.append(match_dict)
            
            return matches
        except Exception as e:
            logger.error(f"Error in metadata filter search: {str(e)}")
            raise
    
    @backoff.on_exception(
        backoff.expo,
        (Exception, ConnectionError),
        max_tries=5,
        jitter=backoff.full_jitter
    )
    async def get_stats(
        self,
        namespace: str = ""
    ) -> Dict[str, Any]:
        """
        Get statistics about the index.
        
        Args:
            namespace: Optional namespace to get statistics for.
            
        Returns:
            Dictionary containing index statistics.
            
        Raises:
            Exception: If there's an error from the Pinecone API.
            ConnectionError: If there's a connection error.
        """
        try:
            # Pinecone describe_index_stats is synchronous, so run in thread pool
            loop = asyncio.get_event_loop()
            
            response = await loop.run_in_executor(
                self._executor,
                partial(
                    self._pinecone_index.describe_index_stats,
                    filter={} if not namespace else {"namespace": namespace}
                )
            )
            
            # Convert to dictionary
            result = {
                "dimension": response.dimension,
                "index_fullness": response.index_fullness,
                "namespaces": response.namespaces
            }
            
            return result
        except Exception as e:
            logger.error(f"Error getting index stats: {str(e)}")
            raise
    
    async def close(self):
        """
        Clean up resources used by the service.
        
        This should be called when the service is no longer needed to ensure
        proper cleanup of resources.
        """
        await self._embedding_service.close() 